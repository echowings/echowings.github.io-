<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>ceph - Tag - echowings</title>
        <link>https://echowings.github.io/tags/ceph/</link>
        <description>ceph - Tag - echowings</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>echo.wings@gmail.com (echowings)</managingEditor>
            <webMaster>echo.wings@gmail.com (echowings)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 01 Jul 2021 14:06:58 &#43;0800</lastBuildDate><atom:link href="https://echowings.github.io/tags/ceph/" rel="self" type="application/rss+xml" /><item>
    <title>How to Delete Ghost Monitor in Ceph Cluster</title>
    <link>https://echowings.github.io/how-to-delete-ghost-monitor-in-ceph-cluster/</link>
    <pubDate>Thu, 01 Jul 2021 14:06:58 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://echowings.github.io/how-to-delete-ghost-monitor-in-ceph-cluster/</guid>
    <description><![CDATA[How to delete ghost monitor in ceph cluster  Today , after I let a new server join pve cluster. ceph mon is stopped. I want to start or delete it , I always got a failed notification. After search and try to fix it. At last I fixed it.Here is what I had do
Issue description 1 2 3 4  root@xa-autotest-hci04:~# pveceph createmon monitor &#39;xa-autotest-hci04&#39; already exists root@xa-autotest-hci04:~# pveceph mon destroy xa-autotest-hci04 no such monitor id &#39;xa-autotest-hci04&#39;   How to fixed it 1 2 3 4 5 6 7 8 9 10 11 12  #stop ceph-mon@xa-autotest-hci04 service systemctl stop ceph-mon@xa-autotest-hci04 #Disable ceph-mon@xa-autotest-hci04 service systemctl disable ceph-mon@xa-autotest-hci04 pveceph purge rm -rf /var/lib/ceph/mon/ceph-xa-autotest-hci04 pveceph createmon #Created symlink /etc/systemd/system/ceph-mon.]]></description>
</item><item>
    <title>How to Let a New Server Join Hci System</title>
    <link>https://echowings.github.io/how-to-let-a-new-server-join-hci-system/</link>
    <pubDate>Thu, 01 Jul 2021 06:38:10 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://echowings.github.io/how-to-let-a-new-server-join-hci-system/</guid>
    <description><![CDATA[##How to let a new server join the exist HCI cluster
1. Insall the pve on the server &ndash;skip&mdash;
2. Let the new server join the pve cluster 1 2  #ssh login the server pvecm add 10.32.4.37   3. configure NTP server 1 2 3 4 5  cat &gt;&gt; /etc/systemd/timesyncd.conf &lt;&lt; EOF NTP=192.168.0.2 192.168.0.3 EOF # Restart systemd-timesyncd service to apply settings systemctl restart systemd-timesyncd   4.]]></description>
</item><item>
    <title>How to Setup Opencase on Pve6</title>
    <link>https://echowings.github.io/how-to-setup-opencase-on-pve6.x/</link>
    <pubDate>Sat, 13 Mar 2021 14:49:17 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://echowings.github.io/how-to-setup-opencase-on-pve6.x/</guid>
    <description><![CDATA[How to setup open cas on pve 6.x Install prepare software  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  apt update &amp;&amp; apt -y dist-upgrade apt install -y make gcc build-essential apt install -y pve-kernel-$(uname -r) apt install -y pve-headers-$(uname -r) OPENCAS_VERSION=20.]]></description>
</item><item>
    <title>How to Import Disk to Ceph</title>
    <link>https://echowings.github.io/proxmox-how-to-import-disk-to-ceph/</link>
    <pubDate>Tue, 07 May 2019 12:06:58 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://echowings.github.io/proxmox-how-to-import-disk-to-ceph/</guid>
    <description><![CDATA[Convert Disk to RAW 1 2 3 4  #qcow2 qemu-img convert -f qcow2 xxx.qcow2 -O raw xxxx.raw #vmware qemu-img convert -f vmdk xxx-flat.vmdk -O raw xxx.raw   Import RAW to ceph 1 2 3 4 5 6  rbd list --pool ${ceph-pool-name} rbd import ./xxx.raw --pool ${ceph-pool-name} rbd rm ${old-file-rm} --pool ${ceph-pool-name] rbd mv xxx.raw ${old-file-rm) rbd list --poll ${ceph-pool-name}  Reference  将qcow2格式的虚拟机文件导入到ceph池里  ]]></description>
</item><item>
    <title>Build Hyper-Converged Infrastructure With Ceph on PVE</title>
    <link>https://echowings.github.io/proxmox-ve-build-hyper-converged-infrastructure-with-ceph-on-pve/</link>
    <pubDate>Mon, 29 Apr 2019 10:56:16 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://echowings.github.io/proxmox-ve-build-hyper-converged-infrastructure-with-ceph-on-pve/</guid>
    <description><![CDATA[Build Hyper-Converged Infrastructure with ceph on PVE&quot; Ceph is really a king of SDS(Software Defin Storage). Opensource. After yeasr evolved, It is enterprise-ready. Today I will build a HCI with ceph on proxmox VE 5.x.
It will end nightmare that someone or montoring system tell you that your service was down, you need be a fire fighter to fixed as soon as possible under tremendous pressure form your boss. With proxmox ve , We can say &rsquo;no more!]]></description>
</item></channel>
</rss>
